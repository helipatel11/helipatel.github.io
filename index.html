<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Prof. Frank Dehne</title>


  

  
  
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"></head><body style="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255);" alink="#000000" link="#000000" vlink="#000000">
<table border="0" width="100%">

  <tbody>
    <tr>
      <td height="27" width="45%">
      <h2>COMP 5704: Parallel Algorithms and Applications in Data Science<br>
</h2>
      </td>
      <td height="27" width="10%">
      <p><br>
      </p>
      </td>
      <td height="27" width="45%">
      <p><b>School of Computer Science</b><br>
      <b>Carleton University, Ottawa, Canada</b></p>
      </td>
    </tr>
  </tbody>
</table>

<hr noshade="noshade">
<h2><font color="#005128">Project Title: </font><font><font color="#005128"> Performance analysis of k-nearest neighbor algorithms</font></font></h2>

<h2><font><font color="#005128">Name: Heli Alpeshkumar Patel</font></font></h2>

<h2><font><font color="#005128">E-Mail: helialpeshkumarpatel@cmail.carleton.ca</font></font></h2>



<hr noshade="noshade">
<b><font color="#005128">Project Outline:</font></b>
<p>Different datasets have grown dramatically in size in recent years. There is a high desire for new strategies that can automatically turn these massive databases into insightful data. Data mining, which unearths patterns in huge databases that are fascinating, significant, and understandable. Business intelligence, customer relationship management, the World Wide Web, scientific simulation,  bioinformatics, e-commerce, and many more domains are important application areas.
<p>Classification is one of the core techniques in data mining, involving the training of a model on a dataset containing class labels and using the output to infer the class of unlabeled objects.The most popular classification method is K-Nearest Neighbor (KNN), one of the top ten most important and commonly applied algorithms. The KNN algorithm is a popular choice for classification. Using the attributes and training dataset, this algorithm aims to characterize new objects. Considering the flaw that the k-nearest neighbor algorithm's (KNN) effectiveness drastically declines as the number of samples rises. Due to KNN's computationally demanding nature, a high-performance implementation is required. Will evaluate my parallel implementation of K-nearest neighbor using the open-source dataset. The experimental results will allow for the drawing of some conclusions.</p>
  <p><b><font color="#005128">Startup Paper(s):</font></b><a href="https://ieeexplore.ieee.org/document/9325700"<font color="#000000">Applying Parallel Processing to Improve the Computation Speed of K-Nearest Neighbor Algorithm</font></a></p>

<p><b><font color="#005128">Deliverables:</font></b></p>

<ul>

  <li>
    <div align="left"><a href="https://helipatel11.github.io/Literature_Review_Heli_A_Patel_COMP5704_Parallel_Processing.pdf" target="_blank"><font color="#000000">Literature Review</font></a> </div>
  </li>
  <li>
    <div align="left"><a href="Presentation_Outline.pdf"><font color="#000000">Presentation Outline</font></a> </div>
  </li>
  <li>
    <div align="left"> <a href="Slide_Presentation.ppt"><font color="#000000">Slide Presentation</font></a> </div>
  </li>
  <li>
    <div align="left"><a href="Final_Paper.pdf"><font color="#000000">Final
Paper</font></a> </div>
  </li>
  <li><a href="Code_and_Data"><font color="#000000">Code and Data</font></a>
</li>
</ul>

<p><b><font color="#005128">Relevant References:</font></b></p>

<ul>

  <li>list all relevant papers and include links to their PDF files</li>
</ul>

</body></html>
